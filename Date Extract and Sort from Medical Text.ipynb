{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Extract and Sort from Medical Text\n",
    "\n",
    "This code reads medical text data and uses regex to extract dates and order them. Each line of the text file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of a variety formats. The code returns a pandas Series in chronological order of the original Series' indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "    \n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       84\n",
       "2        2\n",
       "3       53\n",
       "4       28\n",
       "5      474\n",
       "6      153\n",
       "7       13\n",
       "8      129\n",
       "9       98\n",
       "10     111\n",
       "11     225\n",
       "12      31\n",
       "13     171\n",
       "14     191\n",
       "15     486\n",
       "16     335\n",
       "17     415\n",
       "18      36\n",
       "19     405\n",
       "20     323\n",
       "21     422\n",
       "22     375\n",
       "23     380\n",
       "24     345\n",
       "25      57\n",
       "26     481\n",
       "27     436\n",
       "28     104\n",
       "29     299\n",
       "      ... \n",
       "470    220\n",
       "471    208\n",
       "472    243\n",
       "473    139\n",
       "474    320\n",
       "475    383\n",
       "476    244\n",
       "477    286\n",
       "478    480\n",
       "479    431\n",
       "480    279\n",
       "481    198\n",
       "482    381\n",
       "483    463\n",
       "484    366\n",
       "485    439\n",
       "486    255\n",
       "487    401\n",
       "488    475\n",
       "489    257\n",
       "490    152\n",
       "491    235\n",
       "492    464\n",
       "493    253\n",
       "494    427\n",
       "495    231\n",
       "496    141\n",
       "497    186\n",
       "498    161\n",
       "499    413\n",
       "Name: index, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_sorter():\n",
    "    \n",
    "    # Your code here\n",
    "\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    # Function to add Century\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    \n",
    "    def add_century(my_date):\n",
    "        if re.search('[-/]\\d{2}\\Z', my_date):  \n",
    "            # Extract position of beginning of pattern\n",
    "            pos = re.search('\\d{2}\\Z', my_date).start()\n",
    "            return my_date[0:pos] + '19' + my_date[pos:]\n",
    "        else:\n",
    "            # if already has century, return the same name\n",
    "            return my_date\n",
    "\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    # Setup\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    \n",
    "    s = pd.Series(doc, name=\"txt\")\n",
    "    df = s.to_frame()\n",
    "    df['original_index'] = df.index\n",
    "\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    # Regex\n",
    "    #---------------------------------------------------------------------------------------\n",
    "\n",
    "    # 1) 04/20/2009; 04/20/09; 4/20/09; 4/3/09 : Line 0~124 (121 entries)\n",
    "    df1 = df[:125]\n",
    "    df1 = df1['txt'].str.extractall(r'(?P<date>[01]?\\d{1}[/-][0123]*\\d{1}[/-][12]*[90]*[78901]\\d{1})')\n",
    "    df1['date'] = df1['date'].apply(add_century)\n",
    "    # Format= 01/01/2008 or 4-13-1982\n",
    "    df1['date'] = pd.to_datetime(df1['date'])\n",
    "\n",
    "    # 2) Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009; : Line 194~227 (34 entries)\n",
    "    df2 = df[194:228]\n",
    "    df2 = df2['txt'].str.extractall(r'(?P<date>(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[.]*[a-z]*[.]*[ \\-]+\\d{1,2}[\\-, ]+\\d{4})', re.IGNORECASE)\n",
    "    df2.date.replace(to_replace='\\.', regex=True, value = '', inplace=True) \n",
    "    df2.date.replace(regex={'anuary':'an', 'anaury':'an', 'ebruary':'eb', 'arch':'ar', 'pril':'pr',\n",
    "                            'une':'un', 'uly':'ul', 'ugust': 'ug', 'eptember':'ep', \n",
    "                            'ctober':'ct', 'ovember':'ov', 'ecember':'ec', 'ecemeber':'ec'}, inplace=True ) \n",
    "    df2.date.replace(to_replace='\\,', regex=True, value = '', inplace=True) \n",
    "    # Format=Apr 11 1990\n",
    "    df2['date'] = pd.to_datetime(df2['date'], format='%b %d %Y')\n",
    "\n",
    "    # 3) 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009 : Line 125~193 (69 entries)\n",
    "    df3 = df[125:194]\n",
    "    #df3.iloc[39]\n",
    "    df3 = df3['txt'].str.extractall(r'(?P<date>\\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[.]*[a-z]*[.]* +\\d{4})', re.IGNORECASE)\n",
    "    df3.date.replace(regex={'anuary':'an', 'anaury':'an', 'ebruary':'eb', 'arch':'ar', 'pril':'pr',\n",
    "                            'une':'un', 'uly':'ul', 'ugust': 'ug', 'eptember':'ep', \n",
    "                            'ctober':'ct', 'ovember':'ov', 'ecember':'ec', 'ecemeber':'ec'}, inplace=True ) \n",
    "    # Format=24 Jan 2001\n",
    "    df3['date'] = pd.to_datetime(df3['date'], format='%d %b %Y')\n",
    "\n",
    "    # 4) Feb 2009; Sep 2009; Oct 2010 : Line 228~342 (115 entries)\n",
    "    df4 = df[228:343]\n",
    "    df4 = df4['txt'].str.extractall(r'(?P<date>(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[.]*[a-z]*[,]* \\d{4})', re.IGNORECASE)\n",
    "    # Data cleanup:\n",
    "    df4.date.replace(to_replace=', ', regex=True, value = ' ', inplace=True) \n",
    "    df4.date.replace(to_replace=' ', regex=True, value = ' 1, ', inplace=True) \n",
    "    df4.date.replace(regex={'anuary':'an', 'anaury':'an', 'ebruary':'eb', 'arch':'ar', 'pril':'pr',\n",
    "                            'une':'un', 'uly':'ul', 'ugust': 'ug', 'eptember':'ep', \n",
    "                            'ctober':'ct', 'ovember':'ov', 'ecember':'ec', 'ecemeber':'ec'}, inplace=True ) \n",
    "    # Format=Sep 1, 1985\n",
    "    df4['date'] = pd.to_datetime(df4['date'], format='%b %d, %Y')\n",
    "\n",
    "    # 5) 6/2008; 12/2009: Line 343~454 (112 entries)\n",
    "    df5 = df[343:455]\n",
    "    df5 = df5['txt'].str.extractall(r'(?P<date>\\d{1,2}/\\d{4})')\n",
    "    df5.date.replace(to_replace='/', regex=True, value = '/01/', inplace=True) \n",
    "    # Format= 6/01/2008\n",
    "    df5['date'] = pd.to_datetime(df5['date'], format='%m/%d/%Y')\n",
    "\n",
    "    # 6) 2009; 2010: Line 455~499 (45 entries)\n",
    "    df6 = df[455:500]\n",
    "    df6 = df6['txt'].str.extractall(r'(?P<date>\\d{4})')\n",
    "    df6['date'] = '01/01/' + df6['date']\n",
    "    # Format= 01/01/2008\n",
    "    df6['date'] = pd.to_datetime(df6['date'], format='%m/%d/%Y')\n",
    "\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    # MERGE and SORT\n",
    "    #---------------------------------------------------------------------------------------\n",
    "\n",
    "    df_all = df1.append(df3, ignore_index=True)\n",
    "    df_all = df_all.append(df2, ignore_index=True)\n",
    "    df_all = df_all.append(df4, ignore_index=True)\n",
    "    df_all = df_all.append(df5, ignore_index=True)\n",
    "    df_all = df_all.append(df6, ignore_index=True)\n",
    "\n",
    "    df_all = df_all.sort_values(\"date\")\n",
    "    df_all.reset_index(inplace=True)\n",
    "\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    # DEBUG\n",
    "    #---------------------------------------------------------------------------------------    \n",
    "    #df_all.iloc[0:100]\n",
    "    #df1.iloc[24][0]\n",
    "    #df6.head(45)\n",
    "    #len(df6)\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    # RETURN\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    \n",
    "    return df_all[\"index\"]\n",
    "\n",
    "date_sorter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
